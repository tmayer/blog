<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Softmax Explained | Thomas MAYER</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Softmax Explained" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understanding the standard activation function for classification." />
<meta property="og:description" content="Understanding the standard activation function for classification." />
<link rel="canonical" href="https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html" />
<meta property="og:url" content="https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html" />
<meta property="og:site_name" content="Thomas MAYER" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-02T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Understanding the standard activation function for classification.","mainEntityOfPage":{"@type":"WebPage","@id":"https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html"},"@type":"BlogPosting","url":"https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html","headline":"Softmax Explained","dateModified":"2020-05-02T00:00:00-05:00","datePublished":"2020-05-02T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tmayer.github.io/blog/feed.xml" title="Thomas MAYER" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-165309645-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Softmax Explained | Thomas MAYER</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Softmax Explained" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understanding the standard activation function for classification." />
<meta property="og:description" content="Understanding the standard activation function for classification." />
<link rel="canonical" href="https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html" />
<meta property="og:url" content="https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html" />
<meta property="og:site_name" content="Thomas MAYER" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-02T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Understanding the standard activation function for classification.","mainEntityOfPage":{"@type":"WebPage","@id":"https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html"},"@type":"BlogPosting","url":"https://tmayer.github.io/blog/deeplearning/2020/05/02/softmax-explained.html","headline":"Softmax Explained","dateModified":"2020-05-02T00:00:00-05:00","datePublished":"2020-05-02T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://tmayer.github.io/blog/feed.xml" title="Thomas MAYER" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-165309645-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
<script type="text/javascript">
require.config({
  paths: {
    jquery: 'https://code.jquery.com/jquery-3.5.0.min',
    plotly: 'https://cdn.plot.ly/plotly-latest.min'
  },

  shim: {
    plotly: {
      deps: ['jquery'],
      exports: 'plotly'
    }
  }
});
</script>

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Thomas MAYER</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Softmax Explained</h1><p class="page-description">Understanding the standard activation function for classification.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-02T00:00:00-05:00" itemprop="datePublished">
        May 2, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deeplearning">deeplearning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/tmayer/blog/tree/master/_notebooks/2020-05-02-softmax-explained.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/tmayer/blog/blob/master/_notebooks/2020-05-02-softmax-explained.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Problem">Problem </a></li>
<li class="toc-entry toc-h2"><a href="#Use-case">Use case </a></li>
<li class="toc-entry toc-h2"><a href="#Two-step-approach">Two-step approach </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Step-1:-Make-everything-positive-while-keeping-the-order-of-elements-constant-(monotonicity)">Step 1: Make everything positive while keeping the order of elements constant (monotonicity) </a></li>
<li class="toc-entry toc-h4"><a href="#Step-2:-Normalize-the-values-to-lie-between-0-and-1.-The-sum-of-all-values-should-be-1">Step 2: Normalize the values to lie between 0 and 1. The sum of all values should be 1 </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Usage-in-Deep-Learning-frameworks">Usage in Deep Learning frameworks </a></li>
<li class="toc-entry toc-h2"><a href="#Caveat">Caveat </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-02-softmax-explained.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Problem">
<a class="anchor" href="#Problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problem<a class="anchor-link" href="#Problem"> </a>
</h2>
<p>Given a bunch of numbers each representing a value for a given item you want to transform them into a metric to identify the highest value with the following properties:</p>
<ul>
<li>the resulting metric should normalize all values, that is the sum of all values should be 1</li>
<li>the metric should favor only one item among the numbers (the one with the highest original value), thus boosting it to make it stand apart more clearly</li>
</ul>
<h2 id="Use-case">
<a class="anchor" href="#Use-case" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use case<a class="anchor-link" href="#Use-case"> </a>
</h2>
<p>Activation function in the last layer of a classification network. Each item stands for a certain class and only one class is to be selected. In the previous layer any kind of activation can result (normally between 0 and infinity) but we want to have a normalized output at the end that tells us which class has been activated.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Two-step-approach">
<a class="anchor" href="#Two-step-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Two-step approach<a class="anchor-link" href="#Two-step-approach"> </a>
</h2>
<ol>
<li>Make all values positive (and boost higher values)</li>
<li>Normalize all values so that they sum to 1.</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">original_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">original_values</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([ 0.46836232, -0.7609481 ,  1.13598762,  0.55041867,  0.71270642,
       -0.99529955,  1.3241378 ,  1.93287689,  0.43763017,  0.59186142])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-1:-Make-everything-positive-while-keeping-the-order-of-elements-constant-(monotonicity)">
<a class="anchor" href="#Step-1:-Make-everything-positive-while-keeping-the-order-of-elements-constant-(monotonicity)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Make everything positive while keeping the order of elements constant (monotonicity)<a class="anchor-link" href="#Step-1:-Make-everything-positive-while-keeping-the-order-of-elements-constant-(monotonicity)"> </a>
</h4>
<p>There are various ways of doing it, but a very convenient one is to use each value as the power of exp</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">step1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">original_values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">step1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1.59737606, 0.46722324, 3.1142477 , 1.73397883, 2.03950355,
       0.36961271, 3.75894301, 6.90935916, 1.54903192, 1.80734952])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check if the ranks in both arrays are still the same (order is preserved)</span>
<span class="kn">from</span> <span class="nn">numpy.testing</span> <span class="kn">import</span> <span class="n">assert_array_equal</span>
<span class="n">assert_array_equal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">step1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">step1</span><span class="p">))</span>

<span class="c1"># check if all values are positive</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">step1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-2:-Normalize-the-values-to-lie-between-0-and-1.-The-sum-of-all-values-should-be-1">
<a class="anchor" href="#Step-2:-Normalize-the-values-to-lie-between-0-and-1.-The-sum-of-all-values-should-be-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: Normalize the values to lie between 0 and 1. The sum of all values should be 1<a class="anchor-link" href="#Step-2:-Normalize-the-values-to-lie-between-0-and-1.-The-sum-of-all-values-should-be-1"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">step2</span> <span class="o">=</span> <span class="n">step1</span><span class="o">/</span><span class="n">step1</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">step2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.06842   , 0.02001245, 0.13339177, 0.07427107, 0.08735753,
       0.01583153, 0.16100584, 0.2959468 , 0.06634929, 0.07741374])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># check if all values are between 0 and 1</span>
<span class="n">softmax_values</span> <span class="o">=</span> <span class="n">step2</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">softmax_values</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">softmax_values</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># check if the values sum up to 1</span>
<span class="kn">from</span> <span class="nn">numpy.testing</span> <span class="kn">import</span> <span class="n">assert_almost_equal</span>
<span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">softmax_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot the original_values versus the softmax values. </span>
<span class="c1"># We sort both arrays in increasing order. You can see that the </span>
<span class="c1"># line for the softmax_values is slightly steeper, </span>
<span class="c1"># thus indicating the boost of higher values.</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">original_values</span><span class="p">));</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">"Original values"</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">softmax_values</span><span class="p">));</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">"Softmax values"</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usage-in-Deep-Learning-frameworks">
<a class="anchor" href="#Usage-in-Deep-Learning-frameworks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage in Deep Learning frameworks<a class="anchor-link" href="#Usage-in-Deep-Learning-frameworks"> </a>
</h2>
<p>All Deep Learning frameworks have softmax functions. Here we show the Keras and PyTorch versions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="n">keras_result</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
    <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">original_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Since Keras's softmax function uses a different approach, </span>
<span class="c1"># the precision of the results varies</span>
<span class="kn">from</span> <span class="nn">numpy.testing</span> <span class="kn">import</span> <span class="n">assert_array_almost_equal</span>
<span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">keras_result</span><span class="p">,</span> <span class="n">softmax_values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">pytorch_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">original_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pytorch_result</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.06842   , 0.02001245, 0.13339177, 0.07427107, 0.08735753,
       0.01583153, 0.16100584, 0.2959468 , 0.06634929, 0.07741374])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">pytorch_result</span><span class="p">,</span> <span class="n">softmax_values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Caveat">
<a class="anchor" href="#Caveat" aria-hidden="true"><span class="octicon octicon-link"></span></a>Caveat<a class="anchor-link" href="#Caveat"> </a>
</h2>
<p>Since softmax boosts the item with the highest value (winner takes it all), you shouldn't be using softmax whenever you want to have more than one element in the output (e.g., in multi-label classification scenarios).</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="tmayer/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/deeplearning/2020/05/02/softmax-explained.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blogging about NLP, Data Science, Visualization and more.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/tmayer" title="tmayer"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/mayerthommy" title="mayerthommy"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
